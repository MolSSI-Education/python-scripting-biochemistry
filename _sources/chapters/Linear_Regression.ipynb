{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "==============="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``````{admonition} Overview\n",
    ":class: overview\n",
    "\n",
    "Questions:\n",
    "\n",
    "* How can I complete linear regression with statistics in Python?\n",
    "\n",
    "Objectives:\n",
    "\n",
    "* Perform linear regression on the data and obteain best fit statistics.\n",
    "\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Linear Regression?\n",
    "When I was a biochemistry grad student, we almost always manipulated our data into a linear format so that we could do linear regression on our handheld calculators. The most prominent example was the manipulation of enzyme kinetic data for Lineweaver-Burke or Eadie-Hofstee plots, so that we could determine the kinetic parameters (**Note**: we'll actually do non-linear curve fitting for enzyme kinetics in a future lesson).  I also remember doing semi-log plots of enzyme inactivation because they were linear. Now we have many more options by using python in Jupyter notebooks.\n",
    "\n",
    "However, some data can still be analyzed by simple linear regression. Perhaps the most common case is the protein assay. Whether you use Lowry, Bradford or BCA methods, it is still most common to use a linear regression fit to the results.\n",
    "\n",
    "In this module, we will explore linear regression in Jupyter notebooks using Python. Please keep in mind - this is just a beginning. If you take a course in data science, you are likely to encounter a much deeper look at linear regression where you explore the relationships among many variables in a dataset.\n",
    "\n",
    "We're going to build on the previous lesson, using the pandas library to import the data for this lesson. Then, we will perform the linear regression using the SciPy library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries you will need\n",
    "\n",
    "In previous lessons, we have used `os`, `numpy`, and `pandas`. In this lesson, we will add the SciPy library, a collection of numerical tools for solving mathematical, scientific, technical and engineering problems (from the [Guru99 Python SciPy Tutorial](https://www.guru99.com/scipy-tutorial.html)). Specific subsets of SciPy are useful for linear algebra (scipy.linalg), optimization and fit (scipy.optimize), statistics and random numbers (scipy.stats), and numerical integration (scipy.integrate).  \n",
    "\n",
    "We will use the dot notation we introduced earlier to access the functions in these libraries. I have expanded our table of libraries to help you keep track of our tools. Please note that the abbreviations listed are just the most common. You can actually define any abbreviation you like, but it is best to use the conventional abbreviations. This will help future coders (including yourself six months from now) as they work with the code. \n",
    "\n",
    "| Library | Uses | Abbreviation |\n",
    "| :------- | :----: | :------------: |\n",
    "| os | file management in operating systems | os |\n",
    "| numpy | calculations | np  | \n",
    "| pandas | data management | pd |\n",
    "| scipy | calculations and statistics | sc or sp | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stages of this module\n",
    "1. Importing the correct libraries\n",
    "1. Importing data with pandas\n",
    "1. Running simple linear regression to print out the desired statistics\n",
    "1. Calculating protein sample concentrations using the linear regression results.\n",
    "\n",
    "The first part of the module is modeled after an exercise in Charlie Weiss's excellent online textbook, *Scientific Computing for Chemists*, which you can find on his GitHub site, [SciCompforChemists](https://github.com/weisscharlesj/SciCompforChemists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data with pandas\n",
    "In this lesson, you will continue to work with `os` and `pandas` to import your data. The exercises in this chapter represent a very straightforward case, but if you look at the code, you can see that it could be applied to much more complex situations. When using pandas, people often append \\_df to the end of a variable name as a reminder that this is a dataframe, so the dataframe that contains our results might be called results_df. The code in the next cell will enable you to create the dataframe for this lesson. Please note that `DataFrame` is a reserved word when working with pandas dataframes, so you should not use that word as a variable name.\n",
    "\n",
    "The data in the csv file includes the concentrations of the standards, where 100 $\\mu$L of standard was added to each test tube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_file = os.path.join('data', 'protein_assay.csv') # gives a path to your csv file\n",
    "results_df = pd.read_csv(protein_file) # use pandas to read the csv file into a dataframe\n",
    "results_df  # display your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a dataframe, you can refer to the data in a column just by the column header. These are strings, so you need to put single or double quotes around them when you use them. In pandas, the terms `series` is often used to refer to the data in a single column in a dataframe. So we are going to use the two column headers to define the data for our linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = results_df['Protein Concentration (mg/mL)']   # setting the x values  \n",
    "ydata = results_df['A595']  # setting the y values    \n",
    "print(xdata,ydata) # checking to make sure everything is in place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with SciPy\n",
    "Now that the data are in place, we simply need to import the stats module from SciPy to perform the linear regression. \n",
    "\n",
    "Notice that the `linregress` function in scipy.stats accepts the two data series and actually generates five values: slope, intercept, r-value, p-value, and standard error. In the next cell all of those variables are assigned in a single command. Then the results are presented with a series of print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(xdata, ydata)\n",
    "print(\"Slope = \", slope)\n",
    "print(\"Intercept = \", intercept)\n",
    "print(\"R-squared = \", r_value**2)\n",
    "print(\"P value = \", p_value)\n",
    "print(\"Standard error = \", std_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for protein concentrations in samples\n",
    "In the next lesson, we will look at plotting these data. For now, let's get some practice using the results of our linear regression to calculate the protein concentrations in typical unknowns. This will be simple math, but it's good practice with using correct syntax. For this exercise, we are going to determine protein concentration in mg/mL. The data shown for the six protein samples in this table can be found in data/protein_samples.csv. In each case 100 $\\mu$L of sample was added to the sample tube for analysis.\n",
    "\n",
    "| Sample # | A$_{595}$ |\n",
    "| :--------: | :----: |\n",
    "| 1 | 0.183 |\n",
    "| 2 | 0.682 |\n",
    "| 3 | 0.759 |\n",
    "| 4 | 1.340 |\n",
    "| 5 | 0.935 |\n",
    "| 6 | 1.013 |\n",
    "\n",
    "We begin with the equation for our standard curve\n",
    "\n",
    "$$\n",
    "A_{595} = slope * ProtConc + intercept\n",
    "$$\n",
    "\n",
    "which we can rearrange to solve for protein concentration.\n",
    "\n",
    "$$\n",
    "ProtConc = \\frac{A_{595} - intercept}{slope}\n",
    "$$\n",
    "\n",
    "Our final equation will then solve for concentration in mg/mL, based on the units for the slope (/mg/mL) and the unitless intercept.\n",
    "\n",
    "Now let's put our unknown sample data in a pandas dataframe, write out the code for the equation and use some neat tricks from pandas to add the concentrations to our table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pandas to import the csv data into a dataframe\n",
    "This is the exact process we used above. We are just repeating it to gain practice. We start by using the os library to point to the csv file. Then we use pandas to read the csv file and write it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = os.path.join('data', 'protein_samples.csv') \n",
    "samples_df = pd.read_csv(samples_file) \n",
    "samples_df  # display your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Equation\n",
    "The next step is to implement the equation we described above in python. You can use the column headers from the pandas dataframe to apply the equation to every row (index) of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_conc = ((samples_df['A-595'] - intercept) / slope)\n",
    "print(protein_conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the column to the dataframe\n",
    "Adding a column to a pandas dataframe is simple - you just use the name of the dataframe followed by the name of the new column in single quotes within square brackets. In this case, we will create the new column and assign the calculated concentration values to that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df['ProtConc'] = protein_conc\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminating values outside the calibration curve (optional)\n",
    "Notice that the calculations cover all absorbance values - python went through each row of the dataframe. \n",
    "\n",
    "There is one more issue we can address - the absorbance value for two of the unknown samples were outside the absorbance values of the standards. Therefore, these concentrations are not experimentally valid and should be reported as being \"Out of Range\". \n",
    "\n",
    "We can make this change in the dataframe by using `loc` to look sequentially at the rows in the dataframe. The syntax here tells python to work with the `samples_df` dataframe, look at one row at a time (`loc`), perform a conditional analysis of the A$_{595}$ value on that row, and change the value for `ProtConc` to `NaN` if the A$_{595}$ < 0.285 (the value for the lowest standard) or A$_{595}$ > 1.118 (the value for the highest standard).\n",
    "\n",
    "`np.nan` is a NumPy function that results in a value of `NaN` (for not a number) as the output. This is typically used when there is no value in a cell, but it still preserves the datatype in that cell as a float. This is preferred to using a string such as 'Out of Range' which would change the datatype for those cells in the column to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df.loc[samples_df['A-595'] < 0.285, 'ProtConc'] = np.nan\n",
    "samples_df.loc[samples_df['A-595'] > 1.118, 'ProtConc'] = np.nan\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Rather than hard-coding the minimum and maximum values for the calibration curve, we could also do this programmatically with the `.min()` and `.max()` functions. \n",
    "\n",
    "```python\n",
    "samples_df.loc[samples_df['A-595'] < results_df['A-595'].min(), 'ProtConc'] = np.nan\n",
    "samples_df.loc[samples_df['A-595'] > results_df['A-595'].max(), 'ProtConc'] = np.nan\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``````{admonition} Exercise\n",
    ":class: exercise\n",
    "\n",
    " Now that you have completed a simple linear regression exercise with protein assay data, here is a problem with a slightly larger dataset, taken from a ground water survey of wells in Texas, kindly provided by  [Houghton-Mifflin](https://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/frame.html). Using the skills you have learned with pandas and SciPy, get the linear regression statistics for the relationship between pH (dependent variable) and bicarbonate levels (ppm in well water in Texas; independent variable). The data are available in the file, Ground_water.csv in the data folder. Once complete, your output should look like this:\n",
    "\n",
    " ```\n",
    "Slope =  -0.0030521595419827677  \n",
    "Intercept =  8.097595134597833  \n",
    "R-squared =  0.1152673937227531  \n",
    "P value =  0.04948248037131796  \n",
    "Standard error =  0.0014948066523110296\n",
    "```\n",
    "\n",
    "```{admonition} Hint\n",
    ":class: solution dropdown\n",
    "\n",
    "You will need to use a multi-step process to complete this exercise.\n",
    "1. Use os to set the file path.\n",
    "2. Use pandas to create a dataframe from the csv file. \n",
    "3. Explore the file to find the column headers for your data. \n",
    "4. Assign your independent and dependent variables.\n",
    "5. Use SciPy.stats to perform linear regression. \n",
    "```\n",
    "\n",
    "    \n",
    "````{admonition} Solution\n",
    ":class: solution dropdown\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "water_file = os.path.join('data', 'Ground_water.csv')\n",
    "water_df = pd.read_csv(water_file)\n",
    "water_df.head() # to see the headers for each series (column)\n",
    "xdata = water_df['Bicarb']\n",
    "ydata = water_df['pH']\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(xdata, ydata)\n",
    "print(\"Slope = \", slope)\n",
    "print(\"Intercept = \", intercept)\n",
    "print(\"R-squared = \", r_value**2)\n",
    "print(\"P value = \", p_value)\n",
    "print(\"Standard error = \", std_err)\n",
    "```\n",
    "````\n",
    "\n",
    "``````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``````{admonition} Key Points\n",
    ":class: key\n",
    "\n",
    "* Use pandas to create dataframes from csv formatted data.</li>\n",
    "  \n",
    "* Use SciPy functions to perform linear regression with statistical output.</li>\n",
    "\n",
    "* Use results from linear regression for lab calculations.</li>\n",
    "\n",
    "``````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
